import { ICustomEngineModule } from './custom';
import { IPromptModule } from './Prompt';
import { SpacesModule } from './hugging-spaces';
import { HuggingFaceInferenceModule, InferenceModel } from './hf-inference';
import { RowsModule } from '../submenus/rows';
const { CustomEngine, TranslationFailException } = require("./Custom") as ICustomEngineModule;
const { parseResponse } = require("./Prompt") as IPromptModule;
const { HugSpacesChat, MissingSpaceAPIKeyException } = require("./hugging-spaces") as SpacesModule;
const { InferenceClient, MissingInferenceAPIKeyException } = require('./hf-inference') as HuggingFaceInferenceModule;
const { createSubmenu } = require("../submenus/rows") as RowsModule;



interface HuggingFaceClientInit { 
    inference_key: string
    spaces_key?: string
}

class HuggingFaceClient { 
    private inferenceClient: InstanceType<typeof InferenceClient>
    private hugSpacesChat: InstanceType<typeof HugSpacesChat>
    constructor({ inference_key, spaces_key }: HuggingFaceClientInit) { 
        this.inferenceClient = new InferenceClient(inference_key)
        this.hugSpacesChat = new HugSpacesChat({ apiKey: spaces_key })
    }

    public async sendPrompt(texts: string[], model: string, target_language: string) { 
        if (model in HugSpacesChat.modelSpaces) { 
            this.hugSpacesChat.connect(model)
            return this.hugSpacesChat.sendPrompt(texts, target_language)

        } 
        return this.inferenceClient.sendPrompt({ 
            texts,
            model,
            target_language,
        })
    }

}

class EngineClient extends CustomEngine { 
    public static models = [...Object.keys(HugSpacesChat.modelSpaces), ...Object.keys(InferenceClient.InferenceModels)]
    public readonly package_name: string
    public readonly package_title: string
    get model_name(): string { return this.getEngine()?.getOptions('model_name') || "Command-R-Plus-08-2024" }
    get api_key(): string { return this.getEngine()?.getOptions('api_key') || "Placeholder" }
    get spaces_key(): string { return this.getEngine()?.getOptions('spaces_key') || '' }
    get rows_translation_models(): string { return this.getEngine()?.getOptions('rows_translation_models') || 'google/gemini-2.0-flash-exp:free,qwen/qwen-2.5-72b-instruct:free,deepseek/deepseek-chat-v3-0324:free,openai/gpt-4o' }

    constructor(thisAddon: Addon) { 
        trans.config.maxRequestLength = 25
        super({ 
            id: thisAddon.package.name,
            name: thisAddon.package.title,
            description: thisAddon.package.description,
            version: thisAddon.package.version,
            author: typeof thisAddon.package.author === 'object'? 
                thisAddon.package.author.name : thisAddon.package.author ?? '',
            maxRequestLength: trans.config.maxRequestLength,
            batchDelay: 1, // 0 is a falsy value, it'll be reverted to the default value (5000)
            optionsForm: { 
                schema: { 
                    model_name: { 
                        type: "string",
                        title: "Model name",
                        description: "Choose the model",
                        required: false,
                        default: "Command-R-Plus-08-2024",
                        enum: Object.keys(InferenceClient.InferenceModels)
                    },
                    api_key: { 
                        type: "string",
                        title: "API key",
                        description: "Insert your HugginFace key to use HuggingFace Inference (Note: Inference â‰  Spaces)",
                        required: false
                    },
                    /* spaces_key: { 
                        type: "string",
                        title: "Spaces API key",
                        description: "Use this field if and only IF a space requires an API key.",
                        required: false
                    }, */
                    rows_translation_models: { 
                        type: "string",
                        title: "Models for rows translation",
                        description: "Type the name of the models to use for translating entire selected rows. format: model1,model2,etc. (order matters)",
                        required: false,
                        default: 'google/gemini-2.0-flash-exp:free,qwen/qwen-2.5-72b-instruct:free,deepseek/deepseek-chat-v3-0324:free,openai/gpt-4o'
                    },
                    target_language: { 
                        type: "string",
                        title: "Target language",
                        description: "Choose the target language",
                        default: "English - US",
                        required: false
                    },
                },

                form: [ 
                    { 
                        key: "model_name"
                    }, { 
                        key: "api_key"
                    }, /* { 
                        key: "spaces_key"
                    },  */{ 
                        key: "rows_translation_models"
                    }, { 
                        key: "target_language"
                    }, 
                ],
                onChange: (_: HTMLInputElement, key: string, value: any) => { 
                    this.update(key, typeof value === "string"? value : "") 
                    if (key === "rows_translation_models") { this.setRowsTranslationContextMenu() }
                    if (key === "model_name" && InferenceClient.InferenceModels[value as InferenceModel] && !this.api_key) { 
                        alert("This model requires an Inference API key!")
                    }
                    /* else if (key === "model_name" && HugSpacesChat.isRestricted(value) && !this.spaces_key) { 
                        alert("This model requires a Space API key!")
                    } */
                }
            }

        })
        this.package_name = thisAddon.package.name
        this.package_title = thisAddon.package.title
        this.setRowsTranslationContextMenu()
    }

    public async fetcher(texts: string[], model: string = this.model_name) { 
        const client = new InferenceClient(this.api_key)
        const response = await client.sendPrompt({ 
            texts,
            model,
            target_language: this.target_language
        })
        .catch(e => { 
            if (e instanceof MissingInferenceAPIKeyException || e instanceof MissingSpaceAPIKeyException) { 
                this.abort()
                throw new TranslationFailException({ 
                    message: e.message,
                    status: 400
                })
            }
            throw new TranslationFailException({
                message: `Error while fetching: ${e}`,
                status: 529
            })
        })

        const result = await parseResponse(response, texts.length) 
        if (result.length !== texts.length || !(result instanceof Array)) { 
            const message = result.length === 0? 
				"Failed to parse JSON."
				: `Unexpected error: length ${result.length} out of ${texts.length}.` + '\n\n' + response;
            throw new TranslationFailException({
                message,
                status: 200
            }) 
        } //else if (result.length > texts.length) { result = result.slice(0, texts.length) }

        return result
    }

    setRowsTranslationContextMenu() { 
        if (!this.package_name || !this.package_title || !this.rows_translation_models) { return }
        trans.gridContextMenu[this.package_name] = createSubmenu({ 
            rowModels: this.rows_translation_models.split(','),
            package_name: this.package_name,
            package_title: this.package_title,
            models: EngineClient.models
        })
    }


}


const EngineModule = { EngineClient }
export type IEngineModule = typeof EngineModule
module.exports = EngineModule